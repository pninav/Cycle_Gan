{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Cycle_GAN_Eval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pninav/Cycle_Gan/blob/main/Cycle_GAN_Eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55h4EHBczJwx"
      },
      "source": [
        "Mounting to google-drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiBi0qHpWDWu",
        "outputId": "524a46a9-f7b6-4e9b-91a7-fa51ff23ea7d"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/Pnina/')\n",
        "os.chdir('/content/Pnina/MyDrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/Pnina/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5whlCxjRV3pB"
      },
      "source": [
        "Cloning CycleGan project (creates a local directory in google drive, initializes a GitHub directory inside it), and installing requirements. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jYq2pVVWCgU"
      },
      "source": [
        "!rm -rf /content/Pnina/MyDrive/Cycle_Gan\n",
        "!git clone https://github.com/pninav/Cycle_Gan.git\n",
        "os.chdir('/content/Pnina/MyDrive/Cycle_Gan')\n",
        "!pip install -r requirements.txt  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4FzRfuOXpuw"
      },
      "source": [
        "Download Kaggle dataset using Kaggle API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHSWXEjUrGU1"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/Pnina/MyDrive/Cycle_Gan/')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/Pnina/MyDrive/Cycle_Gan/kaggle/'\n",
        "!mkdir -p kaggle_dataset\n",
        "os.chdir('/content/Pnina/MyDrive/Cycle_Gan/kaggle_dataset')\n",
        "!kaggle competitions download -c gan-getting-started "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeBBUMmrx2cq"
      },
      "source": [
        "Create Cycle_Gan folder (the GitHub files will be transferred there)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8h1H13xFfdp"
      },
      "source": [
        "os.chdir('/content/Pnina/MyDrive/Cycle_Gan/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r70Sc4GOyWg7"
      },
      "source": [
        "Run the train.py notebook - Train the CycleGAN model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAKHPkMGhF70"
      },
      "source": [
        "!python train.py --cuda --eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI_DxqJWn2eq"
      },
      "source": [
        "Create output & run folders\n",
        "Download the training weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfufwDeEEz8b"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/Pnina/MyDrive/Cycle_Gan/')\n",
        "!mkdir -p output\n",
        "os.chdir('/content/Pnina/MyDrive/Cycle_Gan/output')\n",
        "!gdown --id 1PLazQWL6YmA8l-W-gEUib2aGSKfRyWgH\n",
        "!gdown --id 1d7on629bJcAsUvi8Pd5j-I95UhrxxN30\n",
        "os.chdir('/content/Pnina/MyDrive/Cycle_Gan/')\n",
        "!mkdir -p runs \n",
        "os.chdir('/content/Pnina/MyDrive/Cycle_Gan/runs')\n",
        "!mkdir -p best \n",
        "os.chdir('/content/Pnina/MyDrive/Cycle_Gan/runs/best')\n",
        "!gdown --id 1rhrDBBOostvxDr39MMk3kY7tHzDi8Ptf\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M70XctDXD62e"
      },
      "source": [
        "Run the test.py notebook While displaying a progress bar for each iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTjMRIpVEHNz"
      },
      "source": [
        "os.chdir('/content/Pnina/MyDrive/Cycle_Gan/')\n",
        "!python test.py --cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1kSGFDdfADz"
      },
      "source": [
        "View sample Images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvWe60qij04X"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from glob import glob\n",
        "import cv2\n",
        "\n",
        "for file in glob('/content/Pnina/MyDrive/Cycle_Gan/output/B_reduced2/*.*'):\n",
        "  img = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
        "  cv2_imshow(img) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9CGn3C0o4Ia"
      },
      "source": [
        "Create an output file (zip file) containing approximately 7000 Monet-style images (the input photos in Monet style).\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S71FNrgTKBqe"
      },
      "source": [
        "!mkdir /content/Pnina/MyDrive/Cycle_Gan/output/submission\n",
        "!zip -r  /content/Pnina/MyDrive/Cycle_Gan/output/submission/Pnina.zip /content/Pnina/MyDrive/Cycle_Gan/output/B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFsknpY8pzZ6"
      },
      "source": [
        "Using TensorBoard - view dashboards such as scalars, graphs, histograms, and others results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RQBxf-p6LiK"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=/content/Pnina/MyDrive/Cycle_Gan/runs  --port 6006\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwnY1atnp4C_"
      },
      "source": [
        "Downloaded a pre-trained model on ImageNet of Inception v3 from http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xWHxobaEa6N"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPZEAWHZC-go"
      },
      "source": [
        "Extract the zip of the inception, especially the weights (classify_image_graph_def.pb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwq4Igr9I1Cg"
      },
      "source": [
        "os.chdir('/content/Pnina/MyDrive/Cycle_Gan')\n",
        "!tar zxvf /content/Pnina/MyDrive/Cycle_Gan/inception-2015-12-05.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HIyT2444t1M"
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip3 install protobuf==3.6.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJIStOjOcbCO"
      },
      "source": [
        "You must restart the runtime in order to use newly installed versions\n",
        "A button will be displayed to confirm a restart to upload an advanced version of TensorFlow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA8n3bFzIuKi"
      },
      "source": [
        "Initialize parameters for MiFID:\n",
        "\n",
        "  I.\tMODEL_PATH: inception weights\n",
        "\n",
        "  II.\tTRAIN_DIR:  thirty reduced Monet images we selected for training\n",
        "  \n",
        "  III.\tOUT_DIR:  thirty Monet style output images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJRD5RJzIe8R"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "MODEL_PATH = '/content/Pnina/MyDrive/Cycle_Gan/classify_image_graph_def.pb'\n",
        "TRAIN_DIR = Path('/content/Pnina/MyDrive/Cycle_Gan/kaggle_dataset/monet_reduced' )\n",
        "OUT_DIR = Path('/content/Pnina/MyDrive/Cycle_Gan/output/B_reduced')\n",
        "OUT_DIR.mkdir(exist_ok=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okxJR9aFxgx_"
      },
      "source": [
        "MiFID - evaluation method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25sopgQQ3mvH"
      },
      "source": [
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from scipy import linalg\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class KernelEvalException(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MiFIDEvaluator(object):\n",
        "    model_path: str\n",
        "    train_images_path: str\n",
        "    feature_path: str = None\n",
        "    imsize: int = 256\n",
        "    output_layer: str = 'Pretrained_Net/pool_3:0'\n",
        "    input_layer: str = 'Pretrained_Net/ExpandDims:0'\n",
        "    output_shape: int = 2048\n",
        "    cosine_distance_eps: float = 0.1\n",
        "    batch_size: int = 1\n",
        "    fid_epsilon: float = 1e-14\n",
        "    \n",
        "    def __post_init__(self):\n",
        "        tf.reset_default_graph()\n",
        "        self.create_model_graph()\n",
        "        with tf.Session() as sess:\n",
        "            if self.feature_path is None:\n",
        "                self.mu2, self.sigma2, self.features2 = self._handle_path_memorization(\n",
        "                    self.train_images_path, sess, is_checksize=False, is_check_png=False)\n",
        "            else:\n",
        "                with np.load(self.feature_path) as f:\n",
        "                    self.mu2, self.sigma2, self.features2 = f['m'], f['s'], f['features']\n",
        "    \n",
        "    def create_model_graph(self):\n",
        "        with tf.gfile.FastGFile(self.model_path, 'rb') as f:\n",
        "            graph_def = tf.GraphDef()\n",
        "            graph_def.ParseFromString(f.read())\n",
        "            _ = tf.import_graph_def(graph_def, name='Pretrained_Net')\n",
        "            \n",
        "    def img_read_checks(self, filename, is_checksize=False, is_check_png=False,check_imsize = 256):\n",
        "        im = Image.open(str(filename)).convert('RGB')\n",
        "        if is_checksize and im.size != (self.imsize, self.imsize):\n",
        "            raise KernelEvalException(f'The images are not of size {check_imsize}')\n",
        "    \n",
        "\n",
        "        if self.imsize is None:\n",
        "            return im\n",
        "        else:\n",
        "            return im.resize((self.imsize, self.imsize), Image.ANTIALIAS)\n",
        "        \n",
        "    def _get_model_layer(self, sess):\n",
        "        layer = sess.graph.get_tensor_by_name(self.output_layer)\n",
        "        ops = layer.graph.get_operations()\n",
        "        for op_idx, op in enumerate(ops):\n",
        "            for o in op.outputs:\n",
        "                shape = o.get_shape()\n",
        "                if shape._dims != []:\n",
        "                    shape = [s.value for s in shape]\n",
        "                    new_shape = []\n",
        "                    for j, s in enumerate(shape):\n",
        "                        if s == 1 and j == 0:\n",
        "                            new_shape.append(None)\n",
        "                        else:\n",
        "                            new_shape.append(s)\n",
        "                    o.__dict__['_shape_val'] = tf.TensorShape(new_shape)\n",
        "        return layer\n",
        "        \n",
        "    def get_activations(self, images, sess):\n",
        "        inception_layer = self._get_model_layer(sess)\n",
        "        n_images = images.shape[0]\n",
        "        if self.batch_size > n_images:\n",
        "            warnings.warn('batch size is bigger than the data size. setting batch size to data size')\n",
        "            self.batch_size = n_images\n",
        "        print(\"NUmber of Images\",n_images)\n",
        "        n_batches = n_images // self.batch_size + 1\n",
        "        pred_arr = np.empty((n_images, self.output_shape))\n",
        "        for i in range(n_batches):\n",
        "            start = i * self.batch_size\n",
        "            if start + self.batch_size < n_images:\n",
        "                end = start + self.batch_size\n",
        "            else:\n",
        "                end = n_images\n",
        "\n",
        "            batch = images[start:end]\n",
        "            pred = sess.run(inception_layer, {self.input_layer: batch})\n",
        "            pred_arr[start:end] = pred.reshape(-1, self.output_shape)\n",
        "        return pred_arr\n",
        "        \n",
        "    def calculate_activation_statistics(self, images, sess):\n",
        "        act = self.get_activations(images, sess)\n",
        "        mu = np.mean(act, axis=0)\n",
        "        sigma = np.cov(act, rowvar=False)\n",
        "        return mu, sigma, act\n",
        "            \n",
        "    def _handle_path_memorization(self, path, sess, is_checksize, is_check_png):\n",
        "        path = Path(path)\n",
        "        files = list(path.glob('*.jpg')) + list(path.glob('*.png'))\n",
        "\n",
        "        # In production we don't resize input images. This is just for demo purpose. \n",
        "        x = np.array([np.array(self.img_read_checks(fn, is_checksize, is_check_png)) for fn in files])\n",
        "        m, s, features = self.calculate_activation_statistics(x, sess)\n",
        "        del x\n",
        "        return m, s, features\n",
        "    \n",
        "    def calculate_frechet_distance(self, mu1, sigma1):\n",
        "        mu1 = np.atleast_1d(mu1)\n",
        "        mu2 = np.atleast_1d(self.mu2)\n",
        "        sigma1 = np.atleast_2d(sigma1)\n",
        "        sigma2 = np.atleast_2d(self.sigma2)\n",
        "\n",
        "        assert mu1.shape == mu2.shape, 'Training and test mean vectors have different lengths'\n",
        "        assert sigma1.shape == sigma2.shape, 'Training and test covariances have different dimensions'\n",
        "\n",
        "        # product might be almost singular\n",
        "        covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "        if not np.isfinite(covmean).all():\n",
        "            msg = f'fid calculation produces singular product; adding {self.eps} to diagonal of cov estimates'\n",
        "            warnings.warn(msg)\n",
        "            offset = np.eye(sigma1.shape[0]) * self.eps\n",
        "            covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
        "            \n",
        "        # numerical error might give slight imaginary component\n",
        "        if np.iscomplexobj(covmean):\n",
        "            if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
        "                m = np.max(np.abs(covmean.imag))\n",
        "                raise ValueError(f'Imaginary component {m}')\n",
        "            covmean = covmean.real\n",
        "        tr_covmean = np.trace(covmean)\n",
        "        return (mu1 - mu2).dot(mu1 - mu2) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n",
        "    \n",
        "    @staticmethod\n",
        "    def normalize_rows(x):\n",
        "        return np.nan_to_num(x / np.linalg.norm(x, ord=2, axis=1, keepdims=True))\n",
        "    \n",
        "    def cosine_distance(self, features1):\n",
        "        features1_nozero = features1[np.sum(features1, axis=1) != 0]\n",
        "        features2_nozero = self.features2[np.sum(self.features2, axis=1) != 0]\n",
        "        norm_f1 = self.normalize_rows(features1_nozero)\n",
        "        norm_f2 = self.normalize_rows(features2_nozero)\n",
        "\n",
        "        d = 1.0 - np.abs(np.matmul(norm_f1, norm_f2.T))\n",
        "        mean_min_d = np.mean(np.min(d, axis=1))\n",
        "        return mean_min_d\n",
        "            \n",
        "    def calculate_kid_given_paths(self, user_images_unzipped_path):\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            m1, s1, features1 = self._handle_path_memorization(\n",
        "                user_images_unzipped_path, sess, is_checksize=True, is_check_png=True)\n",
        "\n",
        "            fid_value = self.calculate_frechet_distance(m1, s1)\n",
        "            distance = self.cosine_distance(features1)\n",
        "            return fid_value, distance\n",
        "        \n",
        "    def distance_thresholding(self, d):\n",
        "        if d < self.cosine_distance_eps:\n",
        "            return d\n",
        "        else:\n",
        "            return 1\n",
        "        \n",
        "    def evaluate(self, user_images_unzipped_path):\n",
        "        fid_value, distance = self.calculate_kid_given_paths(user_images_unzipped_path)\n",
        "        distance = self.distance_thresholding(distance)\n",
        "        return fid_value, distance, fid_value / (distance + self.fid_epsilon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGBJjARhEV-R"
      },
      "source": [
        "Get MiFID score.\n",
        "\n",
        "In this notebook, I added the functions of calculating the MiFID and activating them to obtain a score for the training model.\n",
        "It is important to note that the MiFID calculation in this notebook is performed for the training of thirty photo images compared to the thirty photos of Monet.\n",
        "In contrast, the output of modeling the models on seven thousand images, which I pass on to the competition in Kegel, will get a higher MiFID score because I trained on seven thousand compared to thirty images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "unczxiWe4F4j"
      },
      "source": [
        "evaluator = MiFIDEvaluator(MODEL_PATH, TRAIN_DIR)\n",
        "fid_value, distance, mi_fid_score = evaluator.evaluate(OUT_DIR)\n",
        "print(f'FID: {fid_value:.5f}')\n",
        "print(f'distance: {distance:.5f}')\n",
        "print(f'MiFID: {mi_fid_score:.5f}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}